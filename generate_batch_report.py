#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨
"""

import json
import statistics
from datetime import datetime
from pathlib import Path


def load_data():
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    raw_file = Path("batch_test_raw_data.json")
    analysis_file = Path("batch_test_analysis.json")
    
    if not raw_file.exists():
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶: batch_test_raw_data.json")
        print("è¯·å…ˆè¿è¡Œ: python batch_test.py")
        return None, None
    
    with open(raw_file, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
    
    if analysis_file.exists():
        with open(analysis_file, 'r', encoding='utf-8') as f:
            analysis = json.load(f)
    else:
        analysis = None
    
    return raw_data, analysis


def generate_markdown_report(raw_data, analysis):
    """ç”ŸæˆMarkdownæŠ¥å‘Š"""
    
    md = "# æ‰¹é‡æµ‹è¯•æ•°æ®åˆ†ææŠ¥å‘Š (Task 1-3 Ã— 10æ¬¡)\n\n"
    md += f"**æµ‹è¯•æ—¥æœŸ**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}\n"
    md += f"**ç³»ç»ŸID**: 2EE26A58\n"
    md += f"**æµ‹è¯•è§„æ¨¡**: Task 1-3 å„10æ¬¡ï¼Œå…±30æ¬¡æµ‹è¯•\n\n"
    md += "---\n\n"
    
    # æ‰§è¡Œæ‘˜è¦
    md += "## ğŸ“Š æ‰§è¡Œæ‘˜è¦\n\n"
    
    for task_id in [1, 2, 3]:
        if task_id not in analysis["tasks_analysis"]:
            continue
        
        ta = analysis["tasks_analysis"][task_id]
        et = ta["execution_time"]
        
        md += f"### Task {task_id}\n\n"
        md += f"- **æµ‹è¯•æ¬¡æ•°**: {ta['runs']}\n"
        md += f"- **æˆåŠŸç‡**: {ta['success_rate']*100:.1f}%\n"
        md += f"- **å¹³å‡æ—¶é—´**: {et['mean']:.2f} Â± {et['stdev']:.2f}ç§’\n"
        md += f"- **æ—¶é—´èŒƒå›´**: [{et['min']:.2f}, {et['max']:.2f}]ç§’\n"
        md += f"- **ä¸­ä½æ•°**: {et['median']:.2f}ç§’\n"
        
        td = ta["target_detection"]
        md += f"- **å¹³å‡æ£€æµ‹**: {td['mean']:.1f} Â± {td['stdev']:.1f}æ¬¡\n"
        
        if task_id == 3 and "obstacle_detection" in ta:
            od = ta["obstacle_detection"]
            md += f"- **éšœç¢æ£€æµ‹**: {od['mean']:.1f} Â± {od['stdev']:.1f}æ¬¡\n"
        
        md += "\n"
    
    md += "---\n\n"
    
    # è¯¦ç»†æ•°æ®è¡¨æ ¼
    md += "## ğŸ“ˆ è¯¦ç»†æµ‹è¯•æ•°æ®\n\n"
    
    for task_id in [1, 2, 3]:
        task_data = [r for r in raw_data if r['task_id'] == task_id]
        if not task_data:
            continue
        
        md += f"### Task {task_id} - æ‰€æœ‰æµ‹è¯•è®°å½•\n\n"
        md += "| æµ‹è¯•# | æ‰§è¡Œæ—¶é—´(ç§’) | ç›®æ ‡æ£€æµ‹ | "
        if task_id == 3:
            md += "éšœç¢æ£€æµ‹ | "
        md += "çŠ¶æ€ |\n"
        
        md += "|-------|-------------|---------|"
        if task_id == 3:
            md += "---------|"
        md += "------|\n"
        
        for r in task_data:
            md += f"| {r['test_number']} | {r['execution_time']:.2f} | {r['target_detected_count']} | "
            if task_id == 3:
                md += f"{r['obstacle_detected_count']} | "
            md += f"{'âœ…' if r['success'] else 'âŒ'} |\n"
        
        md += "\n"
    
    # ç»Ÿè®¡å›¾è¡¨
    md += "---\n\n"
    md += "## ğŸ“Š ç»Ÿè®¡åˆ†æ\n\n"
    
    # å¯¹æ¯”è¡¨æ ¼
    md += "### ä¸‰ä»»åŠ¡å¯¹æ¯”\n\n"
    md += "| æŒ‡æ ‡ | Task 1 | Task 2 | Task 3 |\n"
    md += "|------|--------|--------|--------|\n"
    
    metrics = [
        ("å¹³å‡æ—¶é—´", lambda ta: f"{ta['execution_time']['mean']:.2f}s"),
        ("æ ‡å‡†å·®", lambda ta: f"{ta['execution_time']['stdev']:.2f}s"),
        ("æœ€å°æ—¶é—´", lambda ta: f"{ta['execution_time']['min']:.2f}s"),
        ("æœ€å¤§æ—¶é—´", lambda ta: f"{ta['execution_time']['max']:.2f}s"),
        ("ç¨³å®šæ€§", lambda ta: f"{(1-ta['execution_time']['stdev']/ta['execution_time']['mean'])*100:.1f}%"),
    ]
    
    for metric_name, metric_func in metrics:
        md += f"| {metric_name} | "
        for task_id in [1, 2, 3]:
            if task_id in analysis["tasks_analysis"]:
                md += f"{metric_func(analysis['tasks_analysis'][task_id])} | "
            else:
                md += "N/A | "
        md += "\n"
    
    md += "\n"
    
    # å…³é”®å‘ç°
    md += "---\n\n"
    md += "## ğŸ¯ å…³é”®å‘ç°\n\n"
    
    times = {tid: analysis["tasks_analysis"][tid]["execution_time"]["mean"] 
             for tid in [1, 2, 3] if tid in analysis["tasks_analysis"]}
    
    if times:  # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        fastest = min(times, key=times.get)
        slowest = max(times, key=times.get)
        
        md += f"1. **æœ€å¿«ä»»åŠ¡**: Task {fastest} (å¹³å‡{times[fastest]:.2f}ç§’)\n"
        md += f"2. **æœ€æ…¢ä»»åŠ¡**: Task {slowest} (å¹³å‡{times[slowest]:.2f}ç§’)\n"
    else:
        md += "âŒ æ— æœ‰æ•ˆæ•°æ®\n"
    
    if 2 in times and 1 in times:
        ratio = times[1] / times[2]
        md += f"3. **Task 2æ•ˆç‡**: æ¯”Task 1å¿« {ratio:.2f}å€\n"
    
    if 3 in times and 1 in times:
        diff = times[1] - times[3]
        md += f"4. **Task 3 vs Task 1**: Task 3{'å¿«' if diff>0 else 'æ…¢'} {abs(diff):.2f}ç§’\n"
    
    # è®¡ç®—å˜å¼‚ç³»æ•°
    if times:  # åªæœ‰æœ‰æ•°æ®æ—¶æ‰è®¡ç®—
        md += "\n### ç¨³å®šæ€§æ’å\n\n"
        stability = []
        for task_id in [1, 2, 3]:
            if task_id in analysis["tasks_analysis"]:
                ta = analysis["tasks_analysis"][task_id]
                cv = ta['execution_time']['stdev'] / ta['execution_time']['mean']
                stability.append((task_id, cv, 1-cv))
        
        stability.sort(key=lambda x: x[1])  # æŒ‰å˜å¼‚ç³»æ•°æ’åº
        
        for rank, (task_id, cv, stability_score) in enumerate(stability, 1):
            md += f"{rank}. Task {task_id}: {stability_score*100:.1f}% (CV={cv:.3f})\n"
    
    md += "\n---\n\n"
    
    # æ•°æ®å¯è§†åŒ–å»ºè®®
    md += "## ğŸ“‰ æ•°æ®åˆ†å¸ƒ\n\n"
    
    for task_id in [1, 2, 3]:
        if task_id not in analysis["tasks_analysis"]:
            continue
        
        ta = analysis["tasks_analysis"][task_id]
        times = ta["execution_time"]["all_values"]
        
        md += f"### Task {task_id} æ‰§è¡Œæ—¶é—´åˆ†å¸ƒ\n\n"
        md += "```\n"
        
        # ç®€å•çš„ASCIIç›´æ–¹å›¾
        min_t = min(times)
        max_t = max(times)
        bins = 5
        bin_width = (max_t - min_t) / bins if max_t > min_t else 1
        
        if bin_width > 0:
            hist = [0] * bins
            for t in times:
                bin_idx = min(int((t - min_t) / bin_width), bins - 1)
                hist[bin_idx] += 1
            
            for i, count in enumerate(hist):
                bin_start = min_t + i * bin_width
                bin_end = bin_start + bin_width
                md += f"[{bin_start:.1f}-{bin_end:.1f}s]: {'â–ˆ' * count} ({count})\n"
        
        md += "```\n\n"
    
    # ä¿å­˜æŠ¥å‘Š
    with open("æ‰¹é‡æµ‹è¯•åˆ†ææŠ¥å‘Š.md", "w", encoding="utf-8") as f:
        f.write(md)
    
    print("âœ“ æŠ¥å‘Šå·²ç”Ÿæˆ: æ‰¹é‡æµ‹è¯•åˆ†ææŠ¥å‘Š.md")


def generate_csv_export(raw_data, analysis):
    """ç”ŸæˆCSVå¯¼å‡º"""
    import csv
    
    # æ±‡æ€»æ•°æ®
    with open("æ‰¹é‡æµ‹è¯•æ±‡æ€».csv", "w", encoding="utf-8-sig", newline='') as f:
        writer = csv.writer(f)
        
        # æ ‡é¢˜
        writer.writerow(["Task", "æµ‹è¯•æ¬¡æ•°", "æˆåŠŸç‡", "å¹³å‡æ—¶é—´", "æ ‡å‡†å·®", "æœ€å°æ—¶é—´", "æœ€å¤§æ—¶é—´", "ä¸­ä½æ•°"])
        
        for task_id in [1, 2, 3]:
            if task_id not in analysis["tasks_analysis"]:
                continue
            
            ta = analysis["tasks_analysis"][task_id]
            et = ta["execution_time"]
            
            writer.writerow([
                f"Task {task_id}",
                ta['runs'],
                f"{ta['success_rate']*100:.1f}%",
                f"{et['mean']:.2f}",
                f"{et['stdev']:.2f}",
                f"{et['min']:.2f}",
                f"{et['max']:.2f}",
                f"{et['median']:.2f}"
            ])
    
    # è¯¦ç»†æ•°æ®
    with open("æ‰¹é‡æµ‹è¯•è¯¦ç»†æ•°æ®.csv", "w", encoding="utf-8-sig", newline='') as f:
        writer = csv.writer(f)
        
        writer.writerow(["Task", "æµ‹è¯•#", "æ—¶é—´æˆ³", "æ‰§è¡Œæ—¶é—´", "ç›®æ ‡æ£€æµ‹", "éšœç¢æ£€æµ‹", "çŠ¶æ€"])
        
        for r in sorted(raw_data, key=lambda x: (x['task_id'], x['test_number'])):
            writer.writerow([
                f"Task {r['task_id']}",
                r['test_number'],
                r['timestamp'],
                f"{r['execution_time']:.2f}",
                r['target_detected_count'],
                r.get('obstacle_detected_count', 0),
                "æˆåŠŸ" if r['success'] else "å¤±è´¥"
            ])
    
    print("âœ“ CSVå·²å¯¼å‡º: æ‰¹é‡æµ‹è¯•æ±‡æ€».csv, æ‰¹é‡æµ‹è¯•è¯¦ç»†æ•°æ®.csv")


def main():
    """ä¸»å‡½æ•°"""
    print("æ­£åœ¨ç”Ÿæˆæ‰¹é‡æµ‹è¯•åˆ†ææŠ¥å‘Š...\n")
    
    raw_data, analysis = load_data()
    
    if not raw_data or not analysis:
        return
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    generate_markdown_report(raw_data, analysis)
    
    # ç”ŸæˆCSVå¯¼å‡º
    generate_csv_export(raw_data, analysis)
    
    print("\nâœ… æ‰€æœ‰æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    print("\næ–‡ä»¶æ¸…å•:")
    print("  - æ‰¹é‡æµ‹è¯•åˆ†ææŠ¥å‘Š.md")
    print("  - æ‰¹é‡æµ‹è¯•æ±‡æ€».csv")
    print("  - æ‰¹é‡æµ‹è¯•è¯¦ç»†æ•°æ®.csv")
    print("  - batch_test_raw_data.json")
    print("  - batch_test_analysis.json")


if __name__ == "__main__":
    main()
